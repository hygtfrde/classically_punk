{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb17f9d-19dd-41c1-a6de-37f734b9e54a",
   "metadata": {},
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a7d5b-3eac-4c85-83ce-a8e68d487548",
   "metadata": {},
   "source": [
    "# Import statements for rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca2e061-c643-4ef2-842e-098eed5bf0e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, LabelEncoder\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCONSTANTS\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RED, GREEN, RESET\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_input_with_timeout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.wrappers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# TENSORFLOW IS REQUIRED (by Keras) EVEN IF NOT ACCESSED\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from CONSTANTS import RED, GREEN, RESET\n",
    "from helpers import get_input_with_timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70153522-2c2c-4b69-a1ff-7acf864a3d63",
   "metadata": {},
   "source": [
    "# MUSIC PROCESSOR CODE\n",
    "## Used to extract audio feature data from the genres dataset\n",
    "## Skip to Model Training code if data is already processed in `df_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af794bb8-f23e-41a5-8dd2-e787e9ed71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "genres_from_dataset = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "fundamental_features_cols = [\n",
    "    'mfcc', 'chroma', 'mel', 'contrast', 'tonnetz'\n",
    "]\n",
    "\n",
    "df_output_dir = 'df_output'\n",
    "\n",
    "class MusicDataProcessor:\n",
    "    def __init__(\n",
    "            self, \n",
    "            dataset_path: str, \n",
    "            file_depth_limit: int, \n",
    "            file_output_name: str, \n",
    "            extract_raw_only: bool,\n",
    "            compute_kde: bool,\n",
    "            compute_ecdf: bool,\n",
    "            pad_and_truncate: bool\n",
    "        ):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.file_depth_limit = file_depth_limit\n",
    "        self.file_output_name = file_output_name\n",
    "        self.genres = genres_from_dataset\n",
    "        self.data = pd.DataFrame(columns=fundamental_features_cols)\n",
    "        self.extract_raw_only = extract_raw_only\n",
    "        self.compute_kde = compute_kde\n",
    "        self.compute_ecdf = compute_ecdf\n",
    "        self.pad_and_truncate = pad_and_truncate\n",
    "\n",
    "        if not os.path.exists(df_output_dir):\n",
    "            os.makedirs(df_output_dir)\n",
    "            print(f\"Directory '{df_output_dir}' created.\")\n",
    "        else:\n",
    "            print(f\"Directory '{df_output_dir}' already exists.\")\n",
    "\n",
    "    def get_data(self):\n",
    "        def encode_array(x):\n",
    "            if isinstance(x, np.ndarray):\n",
    "                # Convert the array to a JSON string\n",
    "                return json.dumps(x.tolist())\n",
    "            return x\n",
    "        encoded_df = self.data.map(encode_array)\n",
    "        encoded_df.to_csv(f'{df_output_dir}/{self.file_output_name}.csv', index=False)\n",
    "        return encoded_df\n",
    "\n",
    "    def compute_stats_and_measures(self, data):\n",
    "        # Compute basic statistics\n",
    "        stats_dict = {\n",
    "            'mean': np.mean(data),\n",
    "            'stddev': np.std(data),\n",
    "            'var': np.var(data),\n",
    "            'min': np.min(data),\n",
    "            'max': np.max(data),\n",
    "            'mad': stats.median_abs_deviation(data),\n",
    "            'kurtosis': kurtosis(data),\n",
    "            'skewness': skew(data)\n",
    "        }\n",
    "        \n",
    "        # Compute ECDF\n",
    "        if self.compute_ecdf:\n",
    "            sorted_data, ecdf = np.sort(data), np.arange(1, len(data) + 1) / len(data)\n",
    "            stats_dict['ecdf_values'] = sorted_data.tolist()\n",
    "            stats_dict['ecdf_proportions'] = ecdf.tolist()\n",
    "        \n",
    "        # Compute KDE\n",
    "        if self.compute_kde:\n",
    "            kde = stats.gaussian_kde(data)\n",
    "            stats_dict['kde'] = kde\n",
    "        \n",
    "        return stats_dict\n",
    "\n",
    "    def extract_features(self, file_path, verbose=None):\n",
    "        try:\n",
    "            target_rows = 13\n",
    "            target_columns = 1293\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            n_fft = min(1024, len(y))\n",
    "            \n",
    "            def pad_or_truncate(feature, target_columns):\n",
    "                # Truncate\n",
    "                if feature.shape[1] > target_columns:\n",
    "                    return feature[:, :target_columns]\n",
    "                # Pad\n",
    "                elif feature.shape[1] < target_columns:\n",
    "                    pad_width = target_columns - feature.shape[1]\n",
    "                    return np.pad(feature, ((0, 0), (0, pad_width)), mode='constant')\n",
    "                return feature\n",
    "\n",
    "            features = {\n",
    "                'mfcc': librosa.feature.mfcc(y=y, sr=sr, n_mfcc=target_rows, n_fft=n_fft),\n",
    "                'chroma': librosa.feature.chroma_stft(y=y, sr=sr, hop_length=n_fft // 4),\n",
    "                'mel': librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft),\n",
    "                'contrast': librosa.feature.spectral_contrast(y=y, sr=sr, n_fft=n_fft),\n",
    "                'tonnetz': librosa.feature.tonnetz(y=y, sr=sr),\n",
    "                'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=n_fft),\n",
    "                'spectral_flatness': librosa.feature.spectral_flatness(y=y),\n",
    "                'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft),\n",
    "                'zero_crossing_rate': librosa.feature.zero_crossing_rate(y=y),\n",
    "                'harmony': librosa.effects.harmonic(y).reshape(1, -1),  # Reshape to 2D array\n",
    "                'perceptr': librosa.effects.percussive(y).reshape(1, -1),  # Reshape to 2D array\n",
    "                'tempo': np.array([librosa.beat.beat_track(y=y, sr=sr)[0]]).reshape(1, 1),  # Ensure shape compatibility\n",
    "                'spectral_rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft),\n",
    "                'rms': librosa.feature.rms(y=y, frame_length=n_fft)\n",
    "            }\n",
    "            \n",
    "            if self.pad_and_truncate:\n",
    "                for key in features:\n",
    "                    if len(features[key].shape) == 2:\n",
    "                        features[key] = pad_or_truncate(features[key], target_columns)\n",
    "                    else:\n",
    "                        # Handle 1D features (e.g., tempo, harmony)\n",
    "                        features[key] = pad_or_truncate(features[key].reshape(1, -1), target_columns)\n",
    "\n",
    "            \n",
    "            if self.extract_raw_only is not None and self.extract_raw_only:\n",
    "                if verbose == 'v':\n",
    "                    for name, array in features.items():\n",
    "                        print(f\"{name.capitalize()} Shape: {array.shape}\")\n",
    "                return features\n",
    "\n",
    "            # Compute statistics for each feature\n",
    "            feature_stats = {}\n",
    "            for feature_name, feature_array in features.items():\n",
    "                if feature_array.ndim == 1:  # If the feature is 1D\n",
    "                    feature_stats.update({\n",
    "                        f'{feature_name}_mean': np.mean(feature_array),\n",
    "                        f'{feature_name}_stddev': np.std(feature_array),\n",
    "                        f'{feature_name}_var': np.var(feature_array),\n",
    "                        f'{feature_name}_min': np.min(feature_array),\n",
    "                        f'{feature_name}_max': np.max(feature_array)\n",
    "                    })\n",
    "                else:  # If the feature is 2D\n",
    "                    num_features = feature_array.shape[0]\n",
    "                    for i in range(num_features):\n",
    "                        feature_i = feature_array[i, :]\n",
    "                        feature_stats.update({\n",
    "                            f'{feature_name}_{i+1}_{key}': value\n",
    "                            for key, value in self.compute_stats_and_measures(feature_i).items()\n",
    "                        })\n",
    "\n",
    "            if verbose == 'v':\n",
    "                for key, value in feature_stats.items():\n",
    "                    print(f\"EXTRACTING: {key}\\n{value}\")\n",
    "\n",
    "            return feature_stats\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        all_data = []\n",
    "        total_files_counter = 0\n",
    "        for genre in self.genres:\n",
    "            counter = 0\n",
    "            genre_dir = os.path.join(self.dataset_path, genre)\n",
    "            for file in os.listdir(genre_dir):\n",
    "                # print(f'File number: {total_files_counter}')\n",
    "                if self.file_depth_limit and counter >= self.file_depth_limit:\n",
    "                    break\n",
    "                file_path = os.path.join(genre_dir, file)\n",
    "                features = self.extract_features(file_path, None)\n",
    "                if features:\n",
    "                    # Flatten and unpack the data structure\n",
    "                    stats_flat = features\n",
    "                    all_data.append({\n",
    "                        'filename': file,\n",
    "                        'genre': genre,\n",
    "                        **stats_flat\n",
    "                    })                                      \n",
    "                    counter += 1\n",
    "                    total_files_counter += 1\n",
    "\n",
    "        self.data = pd.DataFrame(all_data)\n",
    "        self.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf079f3-4079-432f-9268-4df04e56d5b8",
   "metadata": {},
   "source": [
    "# Run Music Processor to Extract Audio Feature Data from song files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59e38a-800e-4132-8877-b005d81bb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dataset_path = '../genres'  # Replace with the path to your audio dataset\n",
    "file_depth_limit = None  # Number of files to process per genre\n",
    "file_output_name = 'full_audio_features'\n",
    "\n",
    "# Create an instance of the MusicDataProcessor\n",
    "processor = MusicDataProcessor(\n",
    "    dataset_path=dataset_path,\n",
    "    file_output_name=file_output_name, \n",
    "    file_depth_limit=file_depth_limit,\n",
    "    extract_raw_only=True,\n",
    "    pad_and_truncate=True,\n",
    "    compute_kde=False,\n",
    "    compute_ecdf=False\n",
    ")\n",
    "\n",
    "# Load data\n",
    "processor.load_data()\n",
    "\n",
    "# Output the processed data\n",
    "print(f\"Data has been processed and saved to CSV file: {file_output_name}.\")\n",
    "print(processor.data.head())  # Display the first few rows of the processed data\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(f\"Time taken: {minutes} minutes and {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41880075-d725-40a7-9c3b-7847fa46f5be",
   "metadata": {},
   "source": [
    "# Model Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2747cb22-d9e2-4a13-b303-fffc38e97128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_array(value):\n",
    "    try: \n",
    "        if isinstance(value, str):\n",
    "            value = value.strip('\"').strip(\"'\")\n",
    "            try:\n",
    "                value = ast.literal_eval(value)\n",
    "                if isinstance(value, list):\n",
    "                    value = np.array(value, dtype=float)\n",
    "                    return value\n",
    "                else:\n",
    "                    print(\"Warning: Evaluated value is not a list.\")\n",
    "            except (ValueError, SyntaxError) as e:\n",
    "                print(f\"Error evaluating string: {e}\")\n",
    "        else:\n",
    "            print('Value not detected as str')\n",
    "        return value\n",
    "    except Exception as e:\n",
    "        print(\"General failure in conversion:\")\n",
    "        print(f'Error: {e}')\n",
    "        return value\n",
    "\n",
    "def read_raw_str_csv_and_split_df(csv_path):\n",
    "    try:\n",
    "        df_input = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading csv into df: {e}\")\n",
    "        return None, None\n",
    "    if df_input is not None:\n",
    "        for col in df_input.columns:\n",
    "            if col not in ['filename', 'genre']:\n",
    "                df_input[col] = df_input[col].apply(convert_string_to_array)\n",
    "        return df_input\n",
    "    else:\n",
    "        print('Error: df_input is None')\n",
    "        return None, None\n",
    "\n",
    "def prepare_data(X, y):\n",
    "    try:\n",
    "        # Step 1: Flatten the features\n",
    "        X_flattened = X.apply(lambda col: col.apply(lambda x: x.flatten()))\n",
    "        # Step 2: Convert the DataFrame of flattened arrays into a 2D NumPy array\n",
    "        X_stacked = np.stack(X_flattened.apply(np.concatenate, axis=1).to_numpy())\n",
    "        # Step 3: Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_stacked)\n",
    "        # Step 4: Encode the target labels (y)\n",
    "        encoder = LabelEncoder()\n",
    "        y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "        return X_scaled, y_encoded, encoder, scaler\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prepare_data: {e}\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_test, y_test, num_features, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=(num_features,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    class EpochLogger(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f\"Epoch {epoch + 1}: loss = {logs['loss']:.4f}, accuracy = {logs['accuracy']:.4f}\")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=300, \n",
    "        batch_size=128, \n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=1,\n",
    "        callbacks=[EpochLogger()]\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e473f7-c9bf-470a-ad66-2e12e4ba9664",
   "metadata": {},
   "source": [
    "# Run Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5de27fb-b77b-457d-8525-4fabf65fa64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/tnwbq8qs0ybbs61jm_vxtjmw0000gn/T/ipykernel_29881/3942574119.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_stacked = np.stack(X_flattened.apply(np.concatenate, axis=1).to_numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.2595 - loss: 12.5883 - val_accuracy: 0.4350 - val_loss: 17.6440\n",
      "Epoch 2/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7492 - loss: 7.5707 - val_accuracy: 0.4900 - val_loss: 12.9360\n",
      "Epoch 3/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8497 - loss: 3.7184 - val_accuracy: 0.5200 - val_loss: 16.2147\n",
      "Epoch 4/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8843 - loss: 1.5545 - val_accuracy: 0.5100 - val_loss: 18.9542\n",
      "Epoch 5/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9147 - loss: 1.9144 - val_accuracy: 0.4750 - val_loss: 19.9121\n",
      "Epoch 6/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9567 - loss: 0.3893 - val_accuracy: 0.4800 - val_loss: 22.8999\n",
      "Epoch 7/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9650 - loss: 0.3354 - val_accuracy: 0.5000 - val_loss: 23.4349\n",
      "Epoch 8/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9575 - loss: 0.3805 - val_accuracy: 0.5250 - val_loss: 21.7517\n",
      "Epoch 9/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9751 - loss: 0.1673 - val_accuracy: 0.5350 - val_loss: 22.5897\n",
      "Epoch 10/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9797 - loss: 0.1252 - val_accuracy: 0.5050 - val_loss: 22.9859\n",
      "Epoch 11/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9810 - loss: 0.1412 - val_accuracy: 0.5400 - val_loss: 22.6495\n",
      "Epoch 12/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9838 - loss: 0.1313 - val_accuracy: 0.5700 - val_loss: 22.3542\n",
      "Epoch 13/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9887 - loss: 0.0608 - val_accuracy: 0.5450 - val_loss: 22.2278\n",
      "Epoch 14/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9825 - loss: 0.3419 - val_accuracy: 0.5200 - val_loss: 25.1684\n",
      "Epoch 15/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9875 - loss: 0.1259 - val_accuracy: 0.5150 - val_loss: 27.7818\n",
      "Epoch 16/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9815 - loss: 0.2403 - val_accuracy: 0.5150 - val_loss: 27.4937\n",
      "Epoch 17/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9976 - loss: 0.0381 - val_accuracy: 0.5350 - val_loss: 26.9580\n",
      "Epoch 18/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9898 - loss: 0.1712 - val_accuracy: 0.5600 - val_loss: 26.1490\n",
      "Epoch 19/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9927 - loss: 0.0840 - val_accuracy: 0.5550 - val_loss: 25.7132\n",
      "Epoch 20/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9912 - loss: 0.1563 - val_accuracy: 0.5600 - val_loss: 25.3178\n",
      "Epoch 21/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9876 - loss: 0.2190 - val_accuracy: 0.5550 - val_loss: 24.1264\n",
      "Epoch 22/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9917 - loss: 0.1146 - val_accuracy: 0.5350 - val_loss: 24.1453\n",
      "Epoch 23/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9893 - loss: 0.0704 - val_accuracy: 0.5500 - val_loss: 24.6043\n",
      "Epoch 24/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9902 - loss: 0.1427 - val_accuracy: 0.5500 - val_loss: 22.6898\n",
      "Epoch 25/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9910 - loss: 0.0677 - val_accuracy: 0.5850 - val_loss: 21.9192\n",
      "Epoch 26/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9906 - loss: 0.1507 - val_accuracy: 0.5450 - val_loss: 21.9821\n",
      "Epoch 27/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9799 - loss: 0.2899 - val_accuracy: 0.5300 - val_loss: 25.4443\n",
      "Epoch 28/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9867 - loss: 0.1469 - val_accuracy: 0.5450 - val_loss: 25.3955\n",
      "Epoch 29/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9925 - loss: 0.0679 - val_accuracy: 0.5550 - val_loss: 24.9674\n",
      "Epoch 30/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9839 - loss: 0.1025 - val_accuracy: 0.5500 - val_loss: 25.2331\n",
      "Epoch 31/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9862 - loss: 0.0815 - val_accuracy: 0.5300 - val_loss: 26.4263\n",
      "Epoch 32/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9868 - loss: 0.1435 - val_accuracy: 0.5450 - val_loss: 25.7155\n",
      "Epoch 33/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9837 - loss: 0.0740 - val_accuracy: 0.5600 - val_loss: 26.3552\n",
      "Epoch 34/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9902 - loss: 0.1008 - val_accuracy: 0.5300 - val_loss: 28.2725\n",
      "Epoch 35/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9812 - loss: 0.1095 - val_accuracy: 0.5350 - val_loss: 31.5647\n",
      "Epoch 36/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9866 - loss: 0.2220 - val_accuracy: 0.5700 - val_loss: 32.0231\n",
      "Epoch 37/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9845 - loss: 0.1478 - val_accuracy: 0.5500 - val_loss: 32.0128\n",
      "Epoch 38/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9893 - loss: 0.0991 - val_accuracy: 0.5400 - val_loss: 31.9464\n",
      "Epoch 39/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9876 - loss: 0.0807 - val_accuracy: 0.5450 - val_loss: 31.7343\n",
      "Epoch 40/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9898 - loss: 0.0695 - val_accuracy: 0.5500 - val_loss: 31.3625\n",
      "Epoch 41/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9956 - loss: 0.0110 - val_accuracy: 0.5400 - val_loss: 31.3576\n",
      "Epoch 42/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9926 - loss: 0.1039 - val_accuracy: 0.5200 - val_loss: 30.6744\n",
      "Epoch 43/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9860 - loss: 0.3493 - val_accuracy: 0.5300 - val_loss: 29.1350\n",
      "Epoch 44/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9928 - loss: 0.0636 - val_accuracy: 0.5200 - val_loss: 29.0401\n",
      "Epoch 45/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9964 - loss: 0.0141 - val_accuracy: 0.5100 - val_loss: 29.0475\n",
      "Epoch 46/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9915 - loss: 0.1168 - val_accuracy: 0.5150 - val_loss: 28.2399\n",
      "Epoch 47/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9973 - loss: 0.0466 - val_accuracy: 0.5350 - val_loss: 28.2221\n",
      "Epoch 48/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9890 - loss: 0.0722 - val_accuracy: 0.5250 - val_loss: 29.2737\n",
      "Epoch 49/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9881 - loss: 0.0774 - val_accuracy: 0.5150 - val_loss: 29.2716\n",
      "Epoch 50/300\n",
      "\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9861 - loss: 0.0751Epoch 50: loss = 0.0952, accuracy = 0.9900\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9871 - loss: 0.0801 - val_accuracy: 0.5350 - val_loss: 29.7487\n",
      "Epoch 51/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9952 - loss: 0.0998 - val_accuracy: 0.5300 - val_loss: 29.9503\n",
      "Epoch 52/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9907 - loss: 0.0681 - val_accuracy: 0.5250 - val_loss: 29.8784\n",
      "Epoch 53/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5150 - val_loss: 30.2189\n",
      "Epoch 54/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9907 - loss: 0.0645 - val_accuracy: 0.5150 - val_loss: 30.4385\n",
      "Epoch 55/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9918 - loss: 0.0540 - val_accuracy: 0.5150 - val_loss: 28.9803\n",
      "Epoch 56/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9909 - loss: 0.0954 - val_accuracy: 0.5500 - val_loss: 28.3887\n",
      "Epoch 57/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9951 - loss: 0.0479 - val_accuracy: 0.5350 - val_loss: 29.4331\n",
      "Epoch 58/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9964 - loss: 0.0154 - val_accuracy: 0.5400 - val_loss: 30.0483\n",
      "Epoch 59/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9886 - loss: 0.1781 - val_accuracy: 0.5250 - val_loss: 30.5339\n",
      "Epoch 60/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9938 - loss: 0.0552 - val_accuracy: 0.5450 - val_loss: 30.0047\n",
      "Epoch 61/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9955 - loss: 0.0194 - val_accuracy: 0.5550 - val_loss: 30.0432\n",
      "Epoch 62/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9989 - loss: 0.0183 - val_accuracy: 0.5450 - val_loss: 30.2488\n",
      "Epoch 63/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9957 - loss: 0.0226 - val_accuracy: 0.5450 - val_loss: 30.4169\n",
      "Epoch 64/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9934 - loss: 0.1040 - val_accuracy: 0.5600 - val_loss: 30.7233\n",
      "Epoch 65/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9940 - loss: 0.0643 - val_accuracy: 0.5500 - val_loss: 31.2309\n",
      "Epoch 66/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9970 - loss: 0.0048 - val_accuracy: 0.5650 - val_loss: 30.6941\n",
      "Epoch 67/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9975 - loss: 0.0308 - val_accuracy: 0.5650 - val_loss: 29.4988\n",
      "Epoch 68/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.5650 - val_loss: 29.0017\n",
      "Epoch 69/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9886 - loss: 0.0672 - val_accuracy: 0.5350 - val_loss: 28.8354\n",
      "Epoch 70/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9897 - loss: 0.0479 - val_accuracy: 0.5600 - val_loss: 29.5590\n",
      "Epoch 71/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9966 - loss: 0.0238 - val_accuracy: 0.5250 - val_loss: 35.1638\n",
      "Epoch 72/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9963 - loss: 0.0359 - val_accuracy: 0.5150 - val_loss: 38.1424\n",
      "Epoch 73/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9923 - loss: 0.0729 - val_accuracy: 0.5350 - val_loss: 37.8098\n",
      "Epoch 74/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9941 - loss: 0.0455 - val_accuracy: 0.5400 - val_loss: 37.7506\n",
      "Epoch 75/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9917 - loss: 0.0433 - val_accuracy: 0.5550 - val_loss: 37.0324\n",
      "Epoch 76/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9913 - loss: 0.0569 - val_accuracy: 0.5300 - val_loss: 35.1630\n",
      "Epoch 77/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9938 - loss: 0.0214 - val_accuracy: 0.5250 - val_loss: 34.0406\n",
      "Epoch 78/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9933 - loss: 0.0347 - val_accuracy: 0.5200 - val_loss: 33.0453\n",
      "Epoch 79/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9912 - loss: 0.0785 - val_accuracy: 0.5300 - val_loss: 32.3809\n",
      "Epoch 80/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9981 - loss: 0.0197 - val_accuracy: 0.5650 - val_loss: 31.2821\n",
      "Epoch 81/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9951 - loss: 0.0357 - val_accuracy: 0.5700 - val_loss: 31.3870\n",
      "Epoch 82/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9944 - loss: 0.4291 - val_accuracy: 0.5450 - val_loss: 33.5180\n",
      "Epoch 83/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9954 - loss: 0.0368 - val_accuracy: 0.5500 - val_loss: 37.1006\n",
      "Epoch 84/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9806 - loss: 0.2351 - val_accuracy: 0.5450 - val_loss: 38.1488\n",
      "Epoch 85/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9946 - loss: 0.0299 - val_accuracy: 0.5650 - val_loss: 37.1374\n",
      "Epoch 86/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9906 - loss: 0.0656 - val_accuracy: 0.5100 - val_loss: 36.4994\n",
      "Epoch 87/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9984 - loss: 0.0083 - val_accuracy: 0.5300 - val_loss: 36.5784\n",
      "Epoch 88/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9904 - loss: 0.0412 - val_accuracy: 0.5250 - val_loss: 36.0742\n",
      "Epoch 89/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9961 - loss: 0.0289 - val_accuracy: 0.5450 - val_loss: 35.9481\n",
      "Epoch 90/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9897 - loss: 0.1460 - val_accuracy: 0.5550 - val_loss: 41.3995\n",
      "Epoch 91/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9925 - loss: 0.1861 - val_accuracy: 0.5150 - val_loss: 41.7161\n",
      "Epoch 92/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9939 - loss: 0.1043 - val_accuracy: 0.5450 - val_loss: 42.2901\n",
      "Epoch 93/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9896 - loss: 0.0910 - val_accuracy: 0.5400 - val_loss: 42.0211\n",
      "Epoch 94/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9932 - loss: 0.0821 - val_accuracy: 0.5350 - val_loss: 39.8771\n",
      "Epoch 95/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9961 - loss: 0.0374 - val_accuracy: 0.5450 - val_loss: 37.3087\n",
      "Epoch 96/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9957 - loss: 0.0200 - val_accuracy: 0.5450 - val_loss: 36.1272\n",
      "Epoch 97/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9971 - loss: 0.0215 - val_accuracy: 0.5400 - val_loss: 36.2962\n",
      "Epoch 98/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9921 - loss: 0.1204 - val_accuracy: 0.5500 - val_loss: 36.5330\n",
      "Epoch 99/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9970 - loss: 0.0214 - val_accuracy: 0.5500 - val_loss: 38.1444\n",
      "Epoch 100/300\n",
      "\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9992 - loss: 0.0103  Epoch 100: loss = 0.0240, accuracy = 0.9975\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9988 - loss: 0.0137 - val_accuracy: 0.5600 - val_loss: 38.9412\n",
      "Epoch 101/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9971 - loss: 0.0819 - val_accuracy: 0.5550 - val_loss: 38.1714\n",
      "Epoch 102/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9968 - loss: 0.0248 - val_accuracy: 0.5400 - val_loss: 38.0698\n",
      "Epoch 103/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9897 - loss: 0.1116 - val_accuracy: 0.5500 - val_loss: 37.6969\n",
      "Epoch 104/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.1411 - val_accuracy: 0.5500 - val_loss: 37.0579\n",
      "Epoch 105/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9947 - loss: 0.0686 - val_accuracy: 0.5750 - val_loss: 36.0518\n",
      "Epoch 106/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.1791 - val_accuracy: 0.5600 - val_loss: 37.3809\n",
      "Epoch 107/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9968 - loss: 0.0285 - val_accuracy: 0.5500 - val_loss: 38.2164\n",
      "Epoch 108/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9917 - loss: 0.1688 - val_accuracy: 0.5350 - val_loss: 41.6045\n",
      "Epoch 109/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 7.2630e-07 - val_accuracy: 0.5400 - val_loss: 43.1419\n",
      "Epoch 110/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9931 - loss: 0.0406 - val_accuracy: 0.5450 - val_loss: 42.6081\n",
      "Epoch 111/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9910 - loss: 0.0617 - val_accuracy: 0.5600 - val_loss: 42.2154\n",
      "Epoch 112/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9954 - loss: 0.3098 - val_accuracy: 0.5100 - val_loss: 47.6707\n",
      "Epoch 113/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9921 - loss: 0.0724 - val_accuracy: 0.5150 - val_loss: 50.9003\n",
      "Epoch 114/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9922 - loss: 0.0737 - val_accuracy: 0.5250 - val_loss: 52.4871\n",
      "Epoch 115/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9908 - loss: 0.1332 - val_accuracy: 0.5350 - val_loss: 54.3123\n",
      "Epoch 116/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9972 - loss: 0.0607 - val_accuracy: 0.5100 - val_loss: 56.4660\n",
      "Epoch 117/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9983 - loss: 0.0331 - val_accuracy: 0.5100 - val_loss: 55.7242\n",
      "Epoch 118/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9919 - loss: 0.0502 - val_accuracy: 0.5200 - val_loss: 54.0933\n",
      "Epoch 119/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9907 - loss: 0.0340 - val_accuracy: 0.5500 - val_loss: 51.5991\n",
      "Epoch 120/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9956 - loss: 0.0320 - val_accuracy: 0.5600 - val_loss: 50.4125\n",
      "Epoch 121/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9962 - loss: 0.0212 - val_accuracy: 0.5500 - val_loss: 50.2217\n",
      "Epoch 122/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9982 - loss: 0.0162 - val_accuracy: 0.5500 - val_loss: 49.7570\n",
      "Epoch 123/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9973 - loss: 0.0288 - val_accuracy: 0.5500 - val_loss: 49.3783\n",
      "Epoch 124/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.0444 - val_accuracy: 0.5400 - val_loss: 47.5872\n",
      "Epoch 125/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9961 - loss: 0.0507 - val_accuracy: 0.5400 - val_loss: 46.2221\n",
      "Epoch 126/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9983 - loss: 0.0034 - val_accuracy: 0.5250 - val_loss: 45.8895\n",
      "Epoch 127/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.5250 - val_loss: 45.7140\n",
      "Epoch 128/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9943 - loss: 0.0748 - val_accuracy: 0.5150 - val_loss: 46.5016\n",
      "Epoch 129/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9983 - loss: 0.0174 - val_accuracy: 0.5400 - val_loss: 46.4405\n",
      "Epoch 130/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9967 - loss: 0.0179 - val_accuracy: 0.5550 - val_loss: 46.3684\n",
      "Epoch 131/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9962 - loss: 0.0648 - val_accuracy: 0.5400 - val_loss: 46.5813\n",
      "Epoch 132/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9987 - loss: 0.0017 - val_accuracy: 0.5300 - val_loss: 47.1066\n",
      "Epoch 133/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9978 - loss: 0.0475 - val_accuracy: 0.5400 - val_loss: 46.6755\n",
      "Epoch 134/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9965 - loss: 0.1072 - val_accuracy: 0.5500 - val_loss: 46.2419\n",
      "Epoch 135/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9941 - loss: 0.0323 - val_accuracy: 0.5500 - val_loss: 45.9393\n",
      "Epoch 136/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9948 - loss: 0.0201 - val_accuracy: 0.5550 - val_loss: 44.7921\n",
      "Epoch 137/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9981 - loss: 0.0185 - val_accuracy: 0.5350 - val_loss: 44.0359\n",
      "Epoch 138/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9963 - loss: 0.0249 - val_accuracy: 0.5450 - val_loss: 47.0245\n",
      "Epoch 139/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9958 - loss: 0.0293 - val_accuracy: 0.5650 - val_loss: 49.2518\n",
      "Epoch 140/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9946 - loss: 0.0696 - val_accuracy: 0.5750 - val_loss: 47.0865\n",
      "Epoch 141/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9937 - loss: 0.0215 - val_accuracy: 0.5750 - val_loss: 45.1692\n",
      "Epoch 142/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9975 - loss: 0.0182 - val_accuracy: 0.5550 - val_loss: 44.2939\n",
      "Epoch 143/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9872 - loss: 0.1252 - val_accuracy: 0.5450 - val_loss: 43.3720\n",
      "Epoch 144/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9928 - loss: 0.0666 - val_accuracy: 0.5450 - val_loss: 45.8736\n",
      "Epoch 145/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9952 - loss: 0.0226 - val_accuracy: 0.5250 - val_loss: 49.0272\n",
      "Epoch 146/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9982 - loss: 0.0324 - val_accuracy: 0.5200 - val_loss: 50.5293\n",
      "Epoch 147/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9981 - loss: 0.0193 - val_accuracy: 0.5050 - val_loss: 54.5150\n",
      "Epoch 148/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9893 - loss: 0.1114 - val_accuracy: 0.5250 - val_loss: 51.3466\n",
      "Epoch 149/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9920 - loss: 0.1160 - val_accuracy: 0.5350 - val_loss: 47.4402\n",
      "Epoch 150/300\n",
      "\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9968 - loss: 0.1154Epoch 150: loss = 0.0492, accuracy = 0.9975\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9970 - loss: 0.0989 - val_accuracy: 0.5250 - val_loss: 46.0840\n",
      "Epoch 151/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9933 - loss: 0.0353 - val_accuracy: 0.5450 - val_loss: 45.6068\n",
      "Epoch 152/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9949 - loss: 0.0310 - val_accuracy: 0.5300 - val_loss: 45.8360\n",
      "Epoch 153/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9894 - loss: 0.0373 - val_accuracy: 0.5300 - val_loss: 46.7146\n",
      "Epoch 154/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9989 - loss: 0.0023 - val_accuracy: 0.5300 - val_loss: 46.8323\n",
      "Epoch 155/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9917 - loss: 0.1426 - val_accuracy: 0.5400 - val_loss: 48.1164\n",
      "Epoch 156/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9905 - loss: 0.1812 - val_accuracy: 0.5450 - val_loss: 48.1701\n",
      "Epoch 157/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9934 - loss: 0.0846 - val_accuracy: 0.5300 - val_loss: 44.9694\n",
      "Epoch 158/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9918 - loss: 0.1214 - val_accuracy: 0.4900 - val_loss: 49.0250\n",
      "Epoch 159/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9896 - loss: 0.1829 - val_accuracy: 0.4900 - val_loss: 53.1935\n",
      "Epoch 160/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9808 - loss: 0.7684 - val_accuracy: 0.5100 - val_loss: 60.2766\n",
      "Epoch 161/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9912 - loss: 0.1535 - val_accuracy: 0.5000 - val_loss: 63.9629\n",
      "Epoch 162/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9835 - loss: 0.2865 - val_accuracy: 0.4900 - val_loss: 57.5489\n",
      "Epoch 163/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9886 - loss: 0.3018 - val_accuracy: 0.4850 - val_loss: 51.0331\n",
      "Epoch 164/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9788 - loss: 0.4395 - val_accuracy: 0.4800 - val_loss: 62.7792\n",
      "Epoch 165/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9861 - loss: 0.2464 - val_accuracy: 0.5100 - val_loss: 68.5043\n",
      "Epoch 166/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9882 - loss: 0.3561 - val_accuracy: 0.5150 - val_loss: 64.9604\n",
      "Epoch 167/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9885 - loss: 0.5897 - val_accuracy: 0.4800 - val_loss: 62.2403\n",
      "Epoch 168/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9920 - loss: 0.3053 - val_accuracy: 0.4550 - val_loss: 65.0673\n",
      "Epoch 169/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9844 - loss: 0.2496 - val_accuracy: 0.4800 - val_loss: 60.0409\n",
      "Epoch 170/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9933 - loss: 0.0231 - val_accuracy: 0.4750 - val_loss: 58.7236\n",
      "Epoch 171/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9922 - loss: 0.1966 - val_accuracy: 0.4800 - val_loss: 60.7826\n",
      "Epoch 172/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9902 - loss: 0.2145 - val_accuracy: 0.4900 - val_loss: 61.9870\n",
      "Epoch 173/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9903 - loss: 0.1790 - val_accuracy: 0.4950 - val_loss: 61.1701\n",
      "Epoch 174/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9921 - loss: 0.1091 - val_accuracy: 0.5050 - val_loss: 60.7798\n",
      "Epoch 175/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9811 - loss: 0.3150 - val_accuracy: 0.5050 - val_loss: 60.0702\n",
      "Epoch 176/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9905 - loss: 0.1414 - val_accuracy: 0.5150 - val_loss: 58.6591\n",
      "Epoch 177/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9924 - loss: 0.4198 - val_accuracy: 0.5350 - val_loss: 57.7209\n",
      "Epoch 178/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0218 - val_accuracy: 0.5500 - val_loss: 57.4356\n",
      "Epoch 179/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9981 - loss: 0.0122 - val_accuracy: 0.5550 - val_loss: 57.0488\n",
      "Epoch 180/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9968 - loss: 0.0387 - val_accuracy: 0.5500 - val_loss: 56.8516\n",
      "Epoch 181/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9931 - loss: 0.0687 - val_accuracy: 0.5800 - val_loss: 57.2844\n",
      "Epoch 182/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9993 - loss: 0.0097 - val_accuracy: 0.5750 - val_loss: 57.9930\n",
      "Epoch 183/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9891 - loss: 0.0833 - val_accuracy: 0.5700 - val_loss: 58.5601\n",
      "Epoch 184/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9946 - loss: 0.1136 - val_accuracy: 0.5750 - val_loss: 58.8747\n",
      "Epoch 185/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9978 - loss: 0.0631 - val_accuracy: 0.5750 - val_loss: 59.9796\n",
      "Epoch 186/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9953 - loss: 0.1135 - val_accuracy: 0.5350 - val_loss: 62.3895\n",
      "Epoch 187/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9959 - loss: 0.0639 - val_accuracy: 0.5100 - val_loss: 66.9841\n",
      "Epoch 188/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9905 - loss: 0.2367 - val_accuracy: 0.4850 - val_loss: 71.7085\n",
      "Epoch 189/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9954 - loss: 0.0241 - val_accuracy: 0.4800 - val_loss: 84.7095\n",
      "Epoch 190/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9859 - loss: 0.6024 - val_accuracy: 0.5000 - val_loss: 68.1066\n",
      "Epoch 191/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9898 - loss: 0.2144 - val_accuracy: 0.5450 - val_loss: 58.6396\n",
      "Epoch 192/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9966 - loss: 0.0168 - val_accuracy: 0.5250 - val_loss: 56.7381\n",
      "Epoch 193/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9915 - loss: 0.5979 - val_accuracy: 0.5200 - val_loss: 63.2391\n",
      "Epoch 194/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9908 - loss: 0.0855 - val_accuracy: 0.5250 - val_loss: 67.6642\n",
      "Epoch 195/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9985 - loss: 0.0496 - val_accuracy: 0.5400 - val_loss: 69.3955\n",
      "Epoch 196/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9951 - loss: 0.1176 - val_accuracy: 0.5300 - val_loss: 64.3895\n",
      "Epoch 197/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9978 - loss: 0.0504 - val_accuracy: 0.5100 - val_loss: 61.1670\n",
      "Epoch 198/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9970 - loss: 0.0316 - val_accuracy: 0.5150 - val_loss: 57.9096\n",
      "Epoch 199/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9958 - loss: 0.0453 - val_accuracy: 0.5000 - val_loss: 56.4188\n",
      "Epoch 200/300\n",
      "\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9967 - loss: 0.1290 Epoch 200: loss = 0.1323, accuracy = 0.9962\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9966 - loss: 0.1298 - val_accuracy: 0.5050 - val_loss: 56.1564\n",
      "Epoch 201/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9970 - loss: 0.0321 - val_accuracy: 0.4850 - val_loss: 56.7719\n",
      "Epoch 202/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9928 - loss: 0.1538 - val_accuracy: 0.4850 - val_loss: 55.7349\n",
      "Epoch 203/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9945 - loss: 0.1058 - val_accuracy: 0.4950 - val_loss: 55.4864\n",
      "Epoch 204/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9978 - loss: 0.0102 - val_accuracy: 0.4950 - val_loss: 54.7827\n",
      "Epoch 205/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9918 - loss: 0.0727 - val_accuracy: 0.4850 - val_loss: 56.8880\n",
      "Epoch 206/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9865 - loss: 0.0804 - val_accuracy: 0.4900 - val_loss: 58.8895\n",
      "Epoch 207/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9891 - loss: 0.4821 - val_accuracy: 0.4900 - val_loss: 55.0855\n",
      "Epoch 208/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9930 - loss: 0.1757 - val_accuracy: 0.5150 - val_loss: 61.3039\n",
      "Epoch 209/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9988 - loss: 0.0814 - val_accuracy: 0.5050 - val_loss: 76.5182\n",
      "Epoch 210/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9861 - loss: 0.4335 - val_accuracy: 0.4750 - val_loss: 82.9770\n",
      "Epoch 211/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9925 - loss: 0.2448 - val_accuracy: 0.5000 - val_loss: 80.5411\n",
      "Epoch 212/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9955 - loss: 0.0587 - val_accuracy: 0.4950 - val_loss: 76.4528\n",
      "Epoch 213/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9964 - loss: 0.1649 - val_accuracy: 0.4950 - val_loss: 74.8144\n",
      "Epoch 214/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9908 - loss: 0.0641 - val_accuracy: 0.4650 - val_loss: 75.8755\n",
      "Epoch 215/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9934 - loss: 0.0537 - val_accuracy: 0.5000 - val_loss: 74.7847\n",
      "Epoch 216/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.9026e-09 - val_accuracy: 0.5100 - val_loss: 74.4759\n",
      "Epoch 217/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9930 - loss: 0.0463 - val_accuracy: 0.5200 - val_loss: 70.1848\n",
      "Epoch 218/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9974 - loss: 0.0294 - val_accuracy: 0.5200 - val_loss: 68.0780\n",
      "Epoch 219/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.7534e-04 - val_accuracy: 0.5250 - val_loss: 67.1609\n",
      "Epoch 220/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.2634e-04 - val_accuracy: 0.5300 - val_loss: 66.9186\n",
      "Epoch 221/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9947 - loss: 0.3428 - val_accuracy: 0.4950 - val_loss: 73.8490\n",
      "Epoch 222/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9965 - loss: 0.1293 - val_accuracy: 0.4850 - val_loss: 83.5346\n",
      "Epoch 223/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9919 - loss: 0.2469 - val_accuracy: 0.4700 - val_loss: 78.6181\n",
      "Epoch 224/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9976 - loss: 0.0905 - val_accuracy: 0.4750 - val_loss: 76.9012\n",
      "Epoch 225/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.6513e-08 - val_accuracy: 0.4850 - val_loss: 76.2164\n",
      "Epoch 226/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9931 - loss: 0.2657 - val_accuracy: 0.5000 - val_loss: 74.4637\n",
      "Epoch 227/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.5200 - val_loss: 72.9005\n",
      "Epoch 228/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9961 - loss: 0.0818 - val_accuracy: 0.5400 - val_loss: 70.9104\n",
      "Epoch 229/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9947 - loss: 0.1146 - val_accuracy: 0.5350 - val_loss: 69.2239\n",
      "Epoch 230/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9956 - loss: 0.0298 - val_accuracy: 0.5400 - val_loss: 67.5172\n",
      "Epoch 231/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9937 - loss: 0.1755 - val_accuracy: 0.5250 - val_loss: 63.8549\n",
      "Epoch 232/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9969 - loss: 0.0291 - val_accuracy: 0.5450 - val_loss: 62.3647\n",
      "Epoch 233/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9926 - loss: 0.2706 - val_accuracy: 0.5350 - val_loss: 57.1510\n",
      "Epoch 234/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9897 - loss: 0.1188 - val_accuracy: 0.5050 - val_loss: 55.1911\n",
      "Epoch 235/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9976 - loss: 0.1041 - val_accuracy: 0.5200 - val_loss: 63.7154\n",
      "Epoch 236/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9968 - loss: 0.0622 - val_accuracy: 0.4800 - val_loss: 68.7665\n",
      "Epoch 237/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9932 - loss: 0.1530 - val_accuracy: 0.5000 - val_loss: 67.9124\n",
      "Epoch 238/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9964 - loss: 0.0478 - val_accuracy: 0.5550 - val_loss: 66.1862\n",
      "Epoch 239/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9952 - loss: 0.0746 - val_accuracy: 0.5450 - val_loss: 66.3402\n",
      "Epoch 240/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9967 - loss: 0.0644 - val_accuracy: 0.5350 - val_loss: 66.8695\n",
      "Epoch 241/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9889 - loss: 0.1472 - val_accuracy: 0.5200 - val_loss: 66.2704\n",
      "Epoch 242/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9937 - loss: 0.0460 - val_accuracy: 0.5000 - val_loss: 66.7463\n",
      "Epoch 243/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9903 - loss: 0.1265 - val_accuracy: 0.5150 - val_loss: 68.2570\n",
      "Epoch 244/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9974 - loss: 0.0392 - val_accuracy: 0.5200 - val_loss: 69.3426\n",
      "Epoch 245/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9949 - loss: 0.0530 - val_accuracy: 0.5100 - val_loss: 70.1300\n",
      "Epoch 246/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9943 - loss: 0.0664 - val_accuracy: 0.5200 - val_loss: 69.5555\n",
      "Epoch 247/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.9855e-07 - val_accuracy: 0.5050 - val_loss: 70.0107\n",
      "Epoch 248/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9983 - loss: 0.0085 - val_accuracy: 0.4950 - val_loss: 70.6394\n",
      "Epoch 249/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9977 - loss: 0.0186 - val_accuracy: 0.5050 - val_loss: 70.4923\n",
      "Epoch 250/300\n",
      "\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 8.6148e-05Epoch 250: loss = 0.0004, accuracy = 1.0000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.7392e-04 - val_accuracy: 0.5100 - val_loss: 69.7050\n",
      "Epoch 251/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9972 - loss: 0.0531 - val_accuracy: 0.5150 - val_loss: 68.5552\n",
      "Epoch 252/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9974 - loss: 0.0367 - val_accuracy: 0.5100 - val_loss: 68.5915\n",
      "Epoch 253/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9969 - loss: 0.0862 - val_accuracy: 0.4900 - val_loss: 68.5978\n",
      "Epoch 254/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9929 - loss: 0.0785 - val_accuracy: 0.5050 - val_loss: 65.1585\n",
      "Epoch 255/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9961 - loss: 0.0505 - val_accuracy: 0.5450 - val_loss: 64.6072\n",
      "Epoch 256/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9925 - loss: 0.5947 - val_accuracy: 0.5250 - val_loss: 64.9377\n",
      "Epoch 257/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9934 - loss: 0.1816 - val_accuracy: 0.5250 - val_loss: 67.0516\n",
      "Epoch 258/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9922 - loss: 0.2309 - val_accuracy: 0.5250 - val_loss: 66.0461\n",
      "Epoch 259/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9973 - loss: 0.4049 - val_accuracy: 0.5150 - val_loss: 66.1142\n",
      "Epoch 260/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 6.2321e-10 - val_accuracy: 0.5150 - val_loss: 66.2430\n",
      "Epoch 261/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9959 - loss: 0.1548 - val_accuracy: 0.5200 - val_loss: 65.4793\n",
      "Epoch 262/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9983 - loss: 0.0343 - val_accuracy: 0.5150 - val_loss: 67.2652\n",
      "Epoch 263/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9989 - loss: 0.0283 - val_accuracy: 0.5150 - val_loss: 68.9497\n",
      "Epoch 264/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9983 - loss: 0.0144 - val_accuracy: 0.5200 - val_loss: 69.9188\n",
      "Epoch 265/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9982 - loss: 0.0315 - val_accuracy: 0.5250 - val_loss: 70.4279\n",
      "Epoch 266/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9982 - loss: 0.0207 - val_accuracy: 0.5250 - val_loss: 70.8795\n",
      "Epoch 267/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9983 - loss: 0.0754 - val_accuracy: 0.5400 - val_loss: 70.6294\n",
      "Epoch 268/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9973 - loss: 0.0862 - val_accuracy: 0.5450 - val_loss: 70.7017\n",
      "Epoch 269/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9973 - loss: 0.0432 - val_accuracy: 0.5350 - val_loss: 70.9800\n",
      "Epoch 270/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9991 - loss: 0.0375 - val_accuracy: 0.5450 - val_loss: 70.8118\n",
      "Epoch 271/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9983 - loss: 0.0199 - val_accuracy: 0.5450 - val_loss: 70.1158\n",
      "Epoch 272/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9993 - loss: 0.0334 - val_accuracy: 0.5550 - val_loss: 70.0500\n",
      "Epoch 273/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9983 - loss: 0.0874 - val_accuracy: 0.5550 - val_loss: 70.4369\n",
      "Epoch 274/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.0684e-07 - val_accuracy: 0.5500 - val_loss: 70.8503\n",
      "Epoch 275/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9946 - loss: 0.0454 - val_accuracy: 0.5250 - val_loss: 72.2047\n",
      "Epoch 276/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9983 - loss: 0.0259 - val_accuracy: 0.5200 - val_loss: 72.8721\n",
      "Epoch 277/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9989 - loss: 0.0324 - val_accuracy: 0.5250 - val_loss: 73.4593\n",
      "Epoch 278/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 8.7931e-08 - val_accuracy: 0.5150 - val_loss: 74.3951\n",
      "Epoch 279/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.6681e-06 - val_accuracy: 0.5200 - val_loss: 75.0077\n",
      "Epoch 280/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 3.7105e-04 - val_accuracy: 0.5050 - val_loss: 75.2886\n",
      "Epoch 281/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9975 - loss: 0.0142 - val_accuracy: 0.5150 - val_loss: 75.0332\n",
      "Epoch 282/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.5200 - val_loss: 74.5716\n",
      "Epoch 283/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9993 - loss: 0.0101 - val_accuracy: 0.5250 - val_loss: 74.2763\n",
      "Epoch 284/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9955 - loss: 0.0828 - val_accuracy: 0.5250 - val_loss: 73.1568\n",
      "Epoch 285/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.4579e-07 - val_accuracy: 0.5300 - val_loss: 72.1699\n",
      "Epoch 286/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.5350 - val_loss: 71.7061\n",
      "Epoch 287/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9991 - loss: 0.0015 - val_accuracy: 0.5550 - val_loss: 72.1360\n",
      "Epoch 288/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.5450 - val_loss: 72.8196\n",
      "Epoch 289/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9983 - loss: 0.0857 - val_accuracy: 0.5600 - val_loss: 71.6958\n",
      "Epoch 290/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.5600 - val_loss: 71.1003\n",
      "Epoch 291/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9966 - loss: 0.1139 - val_accuracy: 0.5550 - val_loss: 70.0808\n",
      "Epoch 292/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9984 - loss: 0.0153 - val_accuracy: 0.5400 - val_loss: 71.3772\n",
      "Epoch 293/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 5.3536e-05 - val_accuracy: 0.5100 - val_loss: 72.9720\n",
      "Epoch 294/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9974 - loss: 0.0193 - val_accuracy: 0.5250 - val_loss: 72.3660\n",
      "Epoch 295/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9968 - loss: 0.0298 - val_accuracy: 0.5300 - val_loss: 71.6679\n",
      "Epoch 296/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.8234e-04 - val_accuracy: 0.5300 - val_loss: 71.1684\n",
      "Epoch 297/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9955 - loss: 0.0296 - val_accuracy: 0.5250 - val_loss: 68.7611\n",
      "Epoch 298/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9956 - loss: 0.0511 - val_accuracy: 0.5150 - val_loss: 68.4104\n",
      "Epoch 299/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.5150 - val_loss: 68.5796\n",
      "Epoch 300/300\n",
      "\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9995 - loss: 0.0591   Epoch 300: loss = 0.1547, accuracy = 0.9987\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9993 - loss: 0.0830 - val_accuracy: 0.5200 - val_loss: 68.4409\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Accuracy: 0.5200\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.45      0.46        20\n",
      "           1       0.86      0.92      0.89        13\n",
      "           2       0.67      0.15      0.24        27\n",
      "           3       0.53      0.38      0.44        21\n",
      "           4       0.33      0.47      0.39        15\n",
      "           5       0.57      0.55      0.56        22\n",
      "           6       0.61      0.92      0.73        25\n",
      "           7       0.41      0.85      0.55        13\n",
      "           8       0.62      0.43      0.51        23\n",
      "           9       0.35      0.38      0.36        21\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.54      0.55      0.51       200\n",
      "weighted avg       0.55      0.52      0.50       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  0  1  0  1  2  0  1  6]\n",
      " [ 0 12  0  0  0  0  0  1  0  0]\n",
      " [ 8  2  4  2  0  4  0  2  1  4]\n",
      " [ 0  0  0  8  2  1  3  5  1  1]\n",
      " [ 0  0  0  0  7  0  5  2  1  0]\n",
      " [ 1  0  0  2  4 12  0  0  1  2]\n",
      " [ 0  0  0  0  1  0 23  0  0  1]\n",
      " [ 0  0  0  0  1  0  0 11  0  1]\n",
      " [ 0  0  1  0  4  2  2  4 10  0]\n",
      " [ 1  0  1  2  2  1  3  2  1  8]]\n",
      "A general error occurred in main block: Cannot clone object '<Sequential name=sequential_4, built=True>' (type <class 'keras.src.models.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n"
     ]
    }
   ],
   "source": [
    "full_dataset_stable = 'df_output/full_audio_features.csv'\n",
    "\n",
    "try:\n",
    "    df_extract = read_raw_str_csv_and_split_df(full_dataset_stable)\n",
    "    \n",
    "    if df_extract is not None:\n",
    "        # Split into X and y\n",
    "        X = df_extract.drop(columns=['filename', 'genre'])\n",
    "        y = df_extract['genre']\n",
    "        categories = y.unique()\n",
    "        num_classes = len(categories)\n",
    "\n",
    "        # Prepare the data\n",
    "        X_scaled, y_encoded, encoder, scaler = prepare_data(X, y)\n",
    "        y_encoded_one_hot = to_categorical(y_encoded, num_classes=num_classes)\n",
    "        if X_scaled is not None and y_encoded is not None:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded_one_hot, test_size=0.2, random_state=42)\n",
    "        else:\n",
    "            print(\"Error in data preparation\")\n",
    "            raise ValueError(\"X_scaled or y_encoded is None\")\n",
    "    \n",
    "        model, history = build_and_train_model(X_train, y_train, X_test, y_test, X_scaled.shape[1], num_classes) \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert y_test and y_pred to class labels\n",
    "        y_test_labels = np.argmax(y_test, axis=1)\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test_labels, y_pred_labels))\n",
    "        \n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"Cross-Validation Accuracy Scores: {scores}\")\n",
    "        print(f\"Mean Accuracy: {scores.mean():.4f}\")\n",
    "\n",
    "        test_accuracy = model.score(X_test, y_test)\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        # Train pipeline\n",
    "        pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        pipeline_score = pipeline.score(X_test, y_test)\n",
    "        print(f\"Pipeline Test Accuracy: {pipeline_score:.4f}\")\n",
    "\n",
    "        # Example parameter grid\n",
    "        param_grid = {'C': [0.1, 1, 10]}\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Best parameters and score\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Error: DataFrame is None\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"A general error occurred in main block: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11ab40-a1b9-4fe9-ab3f-0e1d7f0a9421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
